input {
  file {
    path => "/gpuz_logs"
    start_position => "beginning"
    sincedb_path => "/sincedb/gpuz.sincedb"
    codec => plain {
      charset => "ISO-8859-1"
    }
    add_field => {
      "RUN generate-logstash-columns.ps1 TO UPDATE THIS BLOCK" => ""
    }
  }
}

filter {
  if [message] =~ /^ *Date *,/ {
    drop {
    }
  }

  csv {
    separator => ","
    skip_empty_columns => true
    columns => [
    "RUN generate-logstash-columns.ps1 TO UPDATE THIS ARRAY"
    ]
  }

  # Remove leading/trailing whitespace from field names
  mutate {
    remove_field => ["Extra_Empty_From_CSV"] # handle the trailing comma

    strip => [
    "RUN generate-logstash-columns.ps1 TO UPDATE THIS ARRAY"
    ]

    convert => {
      "RUN generate-logstash-columns.ps1 TO UPDATE THIS BLOCK" => ""
    }
  }

  date {
    match => ["Date", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
    timezone => "Europe/Warsaw"
  }
}

output {
  elasticsearch {
    hosts => ["${ES_HOST}:${ES_PORT}"]
    index => "gpuz-metrics-%{+YYYY.MM.dd}"
  }
  #stdout {
  #  codec => rubydebug
  #}
}
